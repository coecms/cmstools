#!/usr/bin/env python
# coding: utf-8

# NOTE: Time comparisons with qstat
# NOTE: Wrong numbers, check user+sys

# Booting python takes ~0.1 seconds, subtract it from any qstat comparisons
# `qstat > /dev/null` is ~0.5-2 seconds
# Seems about the same for individual users (`qstat -u xxx999`)
# `qstat -ft > /dev/null` takes ~2-5 seconds (usually)
# `qstat -Qf` is usually 0.1-1 seconds
# qstat itself can lag (sometimes more than 8sec)
# nqstat is about 4-8 seconds (probably waiting on qstat -ft)

# Performance improvement is only possible if we don't `qstat -ft`
# Python isn't the problem

# NOTE: Parsing qstat output is stupid, we need access to PBS libraries

import argparse
from collections import defaultdict
import os
import shlex
import subprocess

default_queues = ['express', 'normal', 'copyq']

#---
def pbs_env_init():

    # Initialise against PBS_CONF_FILE
    # TODO: Resolve missing file case

    pbs_conf_fpath = '/etc/pbs.conf'
    with open(pbs_conf_fpath) as pbs_conf:
        for line in pbs_conf:
            try:
                key, value = line.split('=')
                os.environ[key] = value.rstrip()
            except ValueError:
                pass


#---
def wt_secs(walltime):
    return float(sum(int(t) * 60 ** i
               for i, t in enumerate(reversed(walltime.split(':')))))


#---
def sizeof_h(size):

    units = ['kb', 'mb', 'gb', 'tb', 'pb', 'eb', 'zb', 'yb']
    nbytes = {u: 2**(10*i) for i, u  in enumerate(units, start=1)}

    # Convert to bytes
    if type(size) == str:
        # TODO: This is retarded, is there a better way?
        num =  int(''.join([s for s in size if s.isdigit()]))
        suffix = ''.join([s for s in size if not s.isdigit()]) 

        if suffix:
            num *=nbytes[suffix]

    elif type(size) == int:
        num = size

    else:
        print('nqstat: error: Unknown memory size')
        sys.exit(1)

    # ... and back again
    for u in ['', 'kib', 'Mib', 'GiB', 'TiB', 'PiB', 'EiB', 'ZiB', 'YiB']:
        if num < 2**10:
            return '{:3}{}'.format(num, u)
        num /= 2**10


#---
def get_qstat_info():
    # TODO: FFS, parsing the entire contents of `qstat -ft`??

    qstat = os.path.join(os.environ['PBS_EXEC'], 'bin', 'qstat')
    cmd = '{} -ft'.format(qstat)

    cmd = shlex.split(cmd)
    output = subprocess.check_output(cmd)

    jentries = (j for j in output.split('Job Id: ') if j)
    jattribs = ((k.split('.')[0], v.replace('\n\t', '').split('\n'))
                for k, v in (j.split('\n', 1) for j in jentries))

    job_status = {k: dict((kk.strip(), vv.strip())
                        for kk, vv in (att.split('=', 1) for att in v if att))
                        for k, v in jattribs}

    # Clean up the results
    for j in job_status:

        # Trim owner name
        username = job_status[j]['Job_Owner'].split('@')[0]
        job_status[j]['Job_Owner'] = username

        for key, value in job_status[j].iteritems():
            if value.isdigit():
                job_status[j][key] = int(value)

    return job_status


#---
def get_queue_info():
    # TODO: Very similar to get_qstat_info; combine them?

    qstat_cmd = os.path.join(os.environ['PBS_EXEC'], 'bin', 'qstat')
    cmd = '{} -Qf'.format(qstat_cmd)

    cmd = shlex.split(cmd)
    output = subprocess.check_output(cmd)

    # Generate the list of queues
    qentries = (q for q in output.split('Queue: ') if q)

    # Generate the queue-attribute pairs per queue
    qattribs = ((k, v.replace('\n\t','').split('\n')) for k, v in
                                        (q.split('\n', 1) for q in qentries))

    # Generate the attribute dictionary per queue
    queue_status = {k: dict((kk.strip(), vv.strip())
                        for kk, vv in (att.split('=', 1) for att in v if att))
                    for k, v in qattribs}

    # Clean up some of the results
    for q in queue_status:
        for key, value in queue_status[q].iteritems():

            if value.isdigit():
                queue_status[q][key] = int(value)
            elif value.lower() == 'true':
                queue_status[q][key] = True
            elif value.lower() == 'false':
                queue_status[q][key] = False

    return queue_status


#---
def display_jobs(queues, jobs):

    headers = ['Job', '', 'User', 'Project', '', '%CPU', 'WallTime',
                'Time Lim', 'vmem', 'mem', 'memlim', 'cpus']

    q_jobinfo = defaultdict(list)
    for qname, qstat in queues.iteritems():

        status = (('open' if qstat['enabled'] else 'closed')
                + ('&run' if qstat['started'] else ''))

        qjobs = {j: jobs[j] for j in jobs if jobs[j]['queue'] == qname}

        for j in qjobs:
            # Job data formatting
            # TODO: Put in get_qstat_info?

            try:
                av_cpu_util = int(wt_secs(jobs[j]['resources_used.cput']) /
                                (wt_secs(jobs[j]['resources_used.walltime'])
                                 * jobs[j]['resources_used.ncpus']) * 100)
            except KeyError:
                av_cpu_util = 0

            walltime_used = jobs[j].get('resources_used.walltime', '')
            vmem_used = jobs[j].get('resources_used.vmem', 0)
            mem_used = jobs[j].get('resources_used.mem', 0)
            mem_limit = jobs[j].get('Resource_List.mem', 0)

            # TODO: Make a columns dict and iterate
            jstate = [j,
                      jobs[j]['job_state'],
                      jobs[j]['Job_Owner'],
                      jobs[j]['project'],
                      jobs[j]['Job_Name'][:8],
                      av_cpu_util,
                      walltime_used,
                      jobs[j]['Resource_List.walltime'],
                      sizeof_h(vmem_used),
                      sizeof_h(mem_used),
                      sizeof_h(mem_limit),
                      jobs[j]['Resource_List.ncpus']
                     ]
            
            q_jobinfo[qname].append(jstate)

    # Formatting
    col_widths = [len(h) for h in headers]

    for qname, j_info in q_jobinfo.iteritems():

        cols = zip(*j_info)
        j_colwidths = [max(len(str(v)) for v in col) for col in cols]

        # Amend for titles
        col_widths = [max(c1, c2) for c1, c2 in zip(j_colwidths, col_widths)]

    # Now display the output
    log_format = ' '.join('%%%ds' % width for width in col_widths)
    print(log_format % tuple(headers))
    print('')
    
    for qname, j_info in q_jobinfo.iteritems():

        qheader = '{} {} '.format(qname, status)
        print(qheader + '=' * max(80 - len(qheader), 0))

        log_format = ' '.join('%%%ds' % width for width in col_widths)

        for j in sorted(j_info, key=lambda x: ord(x[1]), reverse=True):
            print log_format % tuple(j)

        print(queue_summary(qname, qjobs))
        print('')


#---
def queue_summary(queue, jobs):

    n_r = sum(jobs[j]['job_state'] == 'R' for j in jobs)
    n_r_cpus = sum(jobs[j]['Resource_List.ncpus'] for j in jobs
                    if jobs[j]['job_state'] == 'R')

    n_s = sum(jobs[j]['job_state'] == 'S' for j in jobs)
    n_s_cpus = sum(jobs[j]['Resource_List.ncpus'] for j in jobs
                    if jobs[j]['job_state'] == 'S')

    n_q = sum(jobs[j]['job_state'] in ('Q', 'H') for j in jobs)
    n_q_cpus = sum(jobs[j]['Resource_List.ncpus'] for j in jobs
                    if jobs[j]['job_state'] in ('Q', 'H'))

    running_log = '{} running jobs ({} CPUs)'.format(n_r, n_r_cpus)
    suspended_log = '{} suspended jobs ({} CPUs)'.format(n_s, n_s_cpus)
    queued_log = '{} queued jobs ({} CPUs)'.format(n_q, n_q_cpus)

    output = ', '.join([running_log, suspended_log, queued_log])

    return output


#---
def nqstat(projects, users, queues, show_all, show_priority):

    # Default input
    if not projects:
        try:
            projects = [os.environ['PROJECT']]
        except KeyError:
            pass

    if not users:
        try:
            users = [os.environ['USER']]
        except KeyError:
            pass

    if not queues:
        queues = default_queues

    # Fetch qstat data
    queues = get_queue_info()
    jobs = get_qstat_info()

    # TODO: Do this during generation of jobs
    jobs = {j: jobs[j] for j in jobs if jobs[j]['project'] in projects
                                     or jobs[j]['Job_Owner'] in users}

    # Display processed results
    display_jobs(queues, jobs)


def nqstat_parse():
    parser = argparse.ArgumentParser()

    parser.add_argument('-P', '--project')
    parser.add_argument('-u', '--user')
    parser.add_argument('-a', '--all',
                        action='store_true',
                        dest='show_all')
    parser.add_argument('-p', '--priority',
                        action='store_true',
                        dest='show_priority')
    parser.add_argument('queues',
                        nargs='*')

    args = parser.parse_args()

    # Low-level parsing
    projects = args.project.split(',') if args.project else None
    users = args.user.split(',') if args.user else None

    return projects, users, args.queues, args.show_all, args.show_priority


if __name__ == '__main__':

    pbs_env_init()
    args = nqstat_parse()
    nqstat(*args)
